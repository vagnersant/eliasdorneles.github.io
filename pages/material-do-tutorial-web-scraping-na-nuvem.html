<!DOCTYPE html>
<html lang="en">
<head>
        <title>Material do Tutorial: Web Scraping na Nuvem</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <link rel="stylesheet" href="/theme/css/main.css" type="text/css" />
        <link href="/" type="application/atom+xml" rel="alternate" title="Hopeful Ramble ATOM Feed" />
<script>
var host = "eliasdorneles.github.io";
if (window.location.host == host && window.location.protocol != "https:") {
  window.location.protocol = "https:";
}
</script>


        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie.css"/>
                <script src="/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie6.css"/><![endif]-->

</head>

<body>
    <a name="top"></a>

<div class="site-container">
        <header id="banner" class="body">
                <h1><a href="/index.html">Hopeful Ramble </a></h1>
                <nav><ul>
                    <li >
                        <a href="/">Blog</a>
                    </li>
                    <li ><a href="/pages/about.html">About</a></li>
                </ul></nav>
        </header><!-- /#banner -->

        
<section id="content" class="body">    
    <header>
        <h1 class="entry-title">Material do Tutorial: Web Scraping na Nuvem</h1>
    </header>
    <h2>Roteiro</h2>
<ul>
<li>Introdução a web scraping com <a href="http://scrapy.org/">Scrapy</a></li>
<li>Conceitos do Scrapy</li>
<li>Hands-on: crawler para versões diferentes dum site de citações</li>
<li>Rodando no <a href="http://scrapinghub.com/platform/">Scrapy Cloud</a></li>
</ul>
<p>O tutorial é 90% Scrapy e 10% Scrapy Cloud.</p>
<blockquote>
<p><strong>Nota:</strong> Scrapy Cloud é o serviço PaaS da Scrapinghub, a empresa em que
trabalho e que é responsável pelo desenvolvimento do Scrapy.</p>
</blockquote>
<h3>Precisa de ajuda?</h3>
<p>Pergunte no <a href="http://pt.stackoverflow.com/tags/scrapy">Stackoverflow em Português usando a tag
scrapy</a> ou pergunte em inglês no
<a href="http://stackoverflow.com/tags/scrapy">Stackoverflow em inglês</a> ou na <a href="https://groups.google.com/forum/#!forum/scrapy-users">lista de
e-mail scrapy-users</a>.</p>
<h2>Introdução a web scraping com Scrapy</h2>
<h3>O que é Scrapy?</h3>
<p><a href="http://scrapy.org/">Scrapy</a> é um framework para crawlear web sites e extrair dados estruturados que
podem ser usados para uma gama de aplicações úteis (data mining, arquivamento,
etc).</p>
<dl>
<dt><em>Scraping:</em></dt>
<dd>extrair dados do conteúdo da página</dd>
<dt><em>Crawling:</em></dt>
<dd>seguir links de uma página a outra</dd>
</dl>
<p>Se você já fez extração de dados de páginas Web antes em Python, são grandes as
chances de você ter usado algo como requests + beautifulsoup. Essas tecnologias
ajudam a fazer <em>scraping</em>.</p>
<p>A grande vantagem de usar Scrapy é que tem suporte de primeira classe a
<em>crawling</em>.</p>
<p>Por exemplo, ele permite configurar o tradeoff de <strong>politeness vs speed</strong> (sem
precisar escrever código pra isso) e já vem com uma configuração útil de
fábrica para crawling habilitada: suporte a cookies, redirecionamento tanto via
HTTP header quanto via tag HTML <code>meta</code>, tenta de novo requisições que falham,
evita requisições duplicadas, etc.</p>
<p>Além disso, o framework é altamente extensível, permite seguir combinando
componentes e crescer um projeto de maneira gerenciável.</p>
<h3>Instalando o Scrapy</h3>
<p>Recomendamos usar virtualenv, e instalar o Scrapy com:</p>
<div class="highlight"><pre><span></span>pip install scrapy
</pre></div>


<p>A dependência chatinha é normalmente o <a href="http://lxml.de/">lxml</a> (que precisa de
algumas bibliotecas C instaladas). Caso tenha dificuldade, <a href="http://doc.scrapy.org/en/latest/intro/install.html#intro-install-platform-notes">consulte as
instruções específicas por
plataforma</a>
ou peça ajuda nos canais citados acima.</p>
<p>Para verificar se o Scrapy está instalado corretamente, rode o comando:</p>
<div class="highlight"><pre><span></span>scrapy version
</pre></div>


<p>A saída que obtenho rodando este comando no meu computador é:</p>
<div class="highlight"><pre><span></span>$ scrapy version
<span class="m">2015</span>-11-14 <span class="m">19</span>:58:56 <span class="o">[</span>scrapy<span class="o">]</span> INFO: Scrapy <span class="m">1</span>.0.3 started <span class="o">(</span>bot: scrapybot<span class="o">)</span>
<span class="m">2015</span>-11-14 <span class="m">19</span>:58:56 <span class="o">[</span>scrapy<span class="o">]</span> INFO: Optional features available: ssl, http11
<span class="m">2015</span>-11-14 <span class="m">19</span>:58:56 <span class="o">[</span>scrapy<span class="o">]</span> INFO: Overridden settings: <span class="o">{}</span>
Scrapy <span class="m">1</span>.0.3
</pre></div>


<h3>Rodando um spider</h3>
<p>Para ter uma noção inicial de como usar o Scrapy, vamos começar rodando um
spider de exemplo.</p>
<p>Crie um arquivo <strong>youtube_spider.py</strong> com o seguinte conteúdo:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">def</span> <span class="nf">first</span><span class="p">(</span><span class="n">sel</span><span class="p">,</span> <span class="n">xpath</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="n">xpath</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">YoutubeChannelLister</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;channel-lister&#39;</span>
    <span class="n">youtube_channel</span> <span class="o">=</span> <span class="s1">&#39;portadosfundos&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;https://www.youtube.com/user/</span><span class="si">%s</span><span class="s1">/videos&#39;</span> <span class="o">%</span> <span class="n">youtube_channel</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">sel</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&quot;ul#channels-browse-content-grid &gt; li&quot;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;link&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">first</span><span class="p">(</span><span class="n">sel</span><span class="p">,</span> <span class="s1">&#39;.//h3/a/@href&#39;</span><span class="p">)),</span>
                <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">first</span><span class="p">(</span><span class="n">sel</span><span class="p">,</span> <span class="s1">&#39;.//h3/a/text()&#39;</span><span class="p">),</span>
                <span class="s1">&#39;views&#39;</span><span class="p">:</span> <span class="n">first</span><span class="p">(</span><span class="n">sel</span><span class="p">,</span> <span class="s2">&quot;.//ul/li[1]/text()&quot;</span><span class="p">),</span>
            <span class="p">}</span>
</pre></div>


<p>Agora, rode o spider com o comando:</p>
<div class="highlight"><pre><span></span>scrapy runspider youtube_spider.py -o portadosfundos.csv
</pre></div>


<p>O scrapy vai procurar um spider no arquivo <strong>youtube_spider.py</strong> e
escrever os dados no arquivo CSV <strong>portadosfundos.csv</strong>.</p>
<p>Caso tudo deu certo, você verá o log da página sendo baixada, os dados sendo
extraídos, e umas estatísticas resumindo o processo no final, algo como:</p>
<div class="highlight"><pre><span></span>...
2015-11-14 20:14:21 [scrapy] DEBUG: Crawled (200) &lt;GET https://www.youtube.com/user/portadosfundos/videos&gt; (referer: None)
2015-11-14 20:14:22 [scrapy] DEBUG: Scraped from &lt;200 https://www.youtube.com/user/portadosfundos/videos&gt;
{&#39;views&#39;: u&#39;323,218 views&#39;, &#39;link&#39;: u&#39;https://www.youtube.com/watch?v=qSqPkRi-UiE&#39;, &#39;title&#39;: u&#39;GAR\xc7ONS&#39;}
2015-11-14 20:14:22 [scrapy] DEBUG: Scraped from &lt;200 https://www.youtube.com/user/portadosfundos/videos&gt;
{&#39;views&#39;: u&#39;1,295,054 views&#39;, &#39;link&#39;: u&#39;https://www.youtube.com/watch?v=yXc8KCxyEyQ&#39;, &#39;title&#39;: u&#39;SUCESSO&#39;}
2015-11-14 20:14:22 [scrapy] DEBUG: Scraped from &lt;200 https://www.youtube.com/user/portadosfundos/videos&gt;
{&#39;views&#39;: u&#39;1,324,448 views&#39;, &#39;link&#39;: u&#39;https://www.youtube.com/watch?v=k9CbDcOT1e8&#39;, &#39;title&#39;: u&#39;BIBLIOTECA&#39;}
...
{&#39;downloader/request_bytes&#39;: 239,
 &#39;downloader/request_count&#39;: 1,
 &#39;downloader/request_method_count/GET&#39;: 1,
 &#39;downloader/response_bytes&#39;: 27176,
 &#39;downloader/response_count&#39;: 1,
 &#39;downloader/response_status_count/200&#39;: 1,
 &#39;item_scraped_count&#39;: 30,
...
2015-11-14 20:14:22 [scrapy] INFO: Spider closed (finished)
</pre></div>


<p>Ao final, verifique os resultados abrindo o arquivo CSV no seu editor de
planilhas favorito.</p>
<p>Se você quiser os dados em JSON, basta mudar a extensão do arquivo de saída:</p>
<div class="highlight"><pre><span></span>scrapy runspider youtube_spider.py -o portadosfundos.json
</pre></div>


<p>Outro formato interessante que o Scrapy suporta é <a href="http://jsonlines.org">JSON lines</a>:</p>
<div class="highlight"><pre><span></span>scrapy runspider youtube_spider.py -o portadosfundos.jl
</pre></div>


<p>Esse formato usa um item JSON em cada linha -- isso é muito útil para arquivos
grandes, porque fica fácil de concatenar dois arquivos ou acrescentar novas
entradas a um arquivo já existente.</p>
<h2>Conceitos do Scrapy</h2>
<h2>Spiders</h2>
<p>Conceito central no Scrapy,
<a href="http://doc.scrapy.org/en/latest/topics/spiders.html">spiders</a> são classes que
herdam de
<a href="http://doc.scrapy.org/en/latest/topics/spiders.html#scrapy-spider"><code>scrapy.Spider</code></a>,
definindo de alguma maneira as requisições iniciais do crawl e como proceder
para tratar os resultados dessas requisições.</p>
<p>Um exemplo simples de spider é:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">SpiderSimples</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;meuspider&#39;</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="s1">&#39;http://example.com&#39;</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;Visitei o site: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
</pre></div>


<p>Se você rodar o spider acima com o comando <code>scrapy runspider</code>, deverá ver no
log as mensagens:</p>
<div class="highlight"><pre><span></span>2015-11-14 21:11:13 [scrapy] DEBUG: Crawled (200) &lt;GET http://example.com&gt; (referer: None)
2015-11-14 21:11:13 [meuspider] DEBUG: Visitei o site: http://example.com
</pre></div>


<p>Como iniciar um crawl a partir de uma lista de URLs é uma tarefa comum,
o Scrapy permite você usar o atribute de classe <code>start_urls</code> em vez de
definir o método <code>start_requests()</code> a cada vez:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">SpiderSimples</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;meuspider&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://example.com&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;Visitei o site: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
</pre></div>


<h2>Callbacks e próximas requisições</h2>
<p>Repare o método <code>parse()</code>, ele recebe um objeto <em>response</em> que representa uma
resposta HTTP, é o que chamamos de um <strong>callback</strong>. Os métodos <strong>callbacks</strong> no
Scrapy são
<a href="https://pythonhelp.wordpress.com/2012/09/03/generator-expressions/">generators</a>
(ou retornam uma lista ou iterável) de objetos que podem ser:</p>
<ul>
<li>dados extraídos (dicionários Python ou objetos que herdam de scrapy.Item)</li>
<li>requisições a serem feitas a seguir (objetos scrapy.Request)</li>
</ul>
<p>O motor do Scrapy itera sobre os objetos resultantes dos callbacks e os
encaminha para o pipeline de dados ou para a fila de próximas requisições a
serem feitas.</p>
<p>Exemplo:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">SpiderSimples</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;meuspider&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://example.com&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;Visitei o site: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
        <span class="k">yield</span> <span class="p">{</span><span class="s1">&#39;url&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">,</span> <span class="s1">&#39;tamanho&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)}</span>

        <span class="n">proxima_url</span> <span class="o">=</span> <span class="s1">&#39;http://www.google.com.br&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;Agora vou para: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">proxima_url</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">proxima_url</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">handle_google</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">handle_google</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;Visitei o google via URL: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
</pre></div>


<p>Antes de rodar o código acima, experimente ler o código e prever
o que ele vai fazer. Depois, rode e verifique se ele fez mesmo
o que você esperava.</p>
<p>Você deverá ver no log algo como:</p>
<div class="highlight"><pre><span></span>2015-11-14 21:32:53 [scrapy] DEBUG: Crawled (200) &lt;GET http://example.com&gt; (referer: None)
2015-11-14 21:32:53 [meuspider] DEBUG: Visitei o site: http://example.com
2015-11-14 21:32:53 [scrapy] DEBUG: Scraped from &lt;200 http://example.com&gt;
{&#39;url&#39;: &#39;http://example.com&#39;, &#39;tamanho&#39;: 1270}
2015-11-14 21:32:53 [meuspider] DEBUG: Agora vou para: http://www.google.com.br
2015-11-14 21:32:53 [scrapy] DEBUG: Crawled (200) &lt;GET http://www.google.com.br&gt; (referer: http://example.com)
2015-11-14 21:32:54 [meuspider] DEBUG: Visitei o google via URL: http://www.google.com.br
2015-11-14 21:32:54 [scrapy] INFO: Closing spider (finished)
</pre></div>


<h3>Settings</h3>
<p>Outro conceito importante do Scrapy são as <strong>settings</strong> (isto é, configurações).
As <strong>settings</strong> oferecem uma maneira de configurar componentes do Scrapy, podendo
ser setadas de várias maneiras, tanto via linha de comando, variáveis de ambiente
em um arquivo <strong>settings.py</strong> no caso de você estar usando um projeto Scrapy ou ainda
diretamente no spider definindo um atributo de classe <code>custom_settings</code>.</p>
<p>Exemplo setando no código do spider um delay de 1.5 segundos entre cada
requisição:</p>
<div class="highlight"><pre><span></span><span class="kr">class</span> <span class="nx">MeuSpider</span><span class="p">(</span><span class="nx">scrapy</span><span class="p">.</span><span class="nx">Spider</span><span class="p">)</span><span class="o">:</span>
    <span class="nx">name</span> <span class="o">=</span> <span class="s1">&#39;meuspider&#39;</span>

    <span class="nx">custom_settings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;DOWNLOAD_DELAY&#39;</span><span class="o">:</span> <span class="mf">1.5</span><span class="p">,</span>
    <span class="p">}</span>
</pre></div>


<p>Para setar uma setting diretamente na linha de comando com <code>scrapy runspider</code>,
use opção <code>-s</code>:</p>
<div class="highlight"><pre><span></span>scrapy runspider meuspider.py -s DOWNLOAD_DELAY=1.5
</pre></div>


<p>Uma setting útil durante o desenvolvimento é a <em>HTTPCACHE_ENABLED</em>, que
habilita uma cache das requisições HTTP -- útil para evitar baixar as
mesmas páginas várias vezes enquanto você refina o código de extração.</p>
<blockquote>
<p><strong>Dica:</strong> na versão atual do Scrapy, a cache por padrão só funciona caso você
esteja dentro de um projeto, que é onde ele coloca um diretório
<code>.scrapy/httpcache</code> para os arquivos de cache. Caso você queira usar a cache
rodando o spider com <code>scrapy runspider</code>, você pode usar um truque "enganar" o
Scrapy criando um arquivo vazio com o nome <code>scrapy.cfg</code> no diretório atual, e
o Scrapy criará a estrutura de diretórios <code>.scrapy/httpcache</code> no diretório
atual.</p>
</blockquote>
<p>Bem, por ora você já deve estar familiarizado com os conceitos importantes do
Scrapy, está na hora de partir para exemplos mais realistas.</p>
<h2>Hands-on: crawler para versões diferentes dum site de citações</h2>
<p>Vamos agora criar um crawler para um site de frases e citações, feito
para esse tutorial e disponível em: <a href="http://spidyquotes.herokuapp.com">http://spidyquotes.herokuapp.com</a></p>
<blockquote>
<p><em>Nota:</em> O código-fonte do site está disponível em:
<a href="https://github.com/eliasdorneles/spidyquotes">https://github.com/eliasdorneles/spidyquotes</a></p>
</blockquote>
<h3>Descrição dos objetivos:</h3>
<p>O site contém uma lista de citações com autor e tags, paginadas com 10 citações
por páginas. Queremos obter todas as citações, juntamente com os respectivos
autores e lista de tags.</p>
<p>Existem 4 variações do site, com o mesmo conteúdo mas usando markup HTML diferente.</p>
<ul>
<li>Versão com markup HTML semântico: <a href="http://spidyquotes.herokuapp.com/">http://spidyquotes.herokuapp.com/</a></li>
<li>Versão com leiaute em tabelas: <a href="http://spidyquotes.herokuapp.com/tableful/">http://spidyquotes.herokuapp.com/tableful/</a></li>
<li>Versão com os dados dentro do código Javascript: <a href="http://spidyquotes.herokuapp.com/js/">http://spidyquotes.herokuapp.com/js/</a></li>
<li>Versão com AJAX e scroll infinito: <a href="http://spidyquotes.herokuapp.com/scroll">http://spidyquotes.herokuapp.com/scroll</a></li>
</ul>
<p>Para ver as diferenças entre cada versão do site, acione a opção "Exibir
código-fonte" (<kbd>Ctrl</kbd>-<kbd>U</kbd>) do menu de contexto do seu
browser.</p>
<blockquote>
<p><strong>Nota:</strong> cuidado com a opção "Inspecionar elemento" do browser para inspecionar
a estrutura do markup. Diferentemente do resultado da opção "Exibir
código-fonte" Usando essa ferramenta, o código que você vê representa as
estruturas que o browser cria para a página, e nem sempre mapeiam diretamente
ao código HTML que veio na requisição HTTP (que é o que você obtém quando usa
o Scrapy), especialmente se a página estiver usando Javascript ou AJAX. Outro
exemplo é o elemento <code>&lt;tbody&gt;</code> que é adicionado automaticamente pelos
browsers em todas as tabelas, mesmo quando não declarado no markup.</p>
</blockquote>
<h3>Spider para a versão com HTML semântico</h3>
<p>Para explorar a página (e a API de scraping do Scrapy), você pode usar
o comando <code>scrapy shell URL</code>:</p>
<div class="highlight"><pre><span></span>scrapy shell http://spidyquotes.herokuapp.com/
</pre></div>


<p>Esse comando abre um shell Python (ou <a href="http://ipython.org">IPython</a>, se você o
tiver instalado no mesmo virtualenv) com o objeto <code>response</code>, o mesmo que você
obteria num método <strong>callback</strong>. Recomendo usar o IPython porque fica mais fácil
de explorar as APIs sem precisar ter que abrir a documentação a cada vez.</p>
<p>Exemplo de exploração com o shell:</p>
<div class="highlight"><pre><span></span>&gt;&gt;&gt; # olhando o fonte HTML, percebi que cada citação está num <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;quote&quot;</span><span class="nt">&gt;</span>
&gt;&gt;&gt; # vamos pegar o primeiro dele, e ver como extrair o texto:
&gt;&gt;&gt; quote = response.css(&#39;.quote&#39;)[0]
&gt;&gt;&gt; quote
    <span class="nt">&lt;Selector</span> <span class="na">xpath=</span><span class="s">u&quot;descendant-or-self::*[@class</span> <span class="err">and</span> <span class="err">contains(concat(&#39;</span> <span class="err">&#39;,</span> <span class="err">normalize-space(@class),</span> <span class="err">&#39;</span> <span class="err">&#39;),</span> <span class="err">&#39;</span> <span class="err">quote</span> <span class="err">&#39;)]&quot;</span> <span class="na">data=</span><span class="s">u&#39;&lt;div</span> <span class="na">class=</span><span class="s">&quot;quote&quot;</span> <span class="err">itemscope</span> <span class="na">itemtype=</span><span class="s">&quot;h&#39;&gt;</span>
<span class="s">&gt;&gt;&gt; print quote.extract()</span>
<span class="s">&lt;div class=&quot;</span><span class="err">quote&quot;</span> <span class="err">itemscope</span> <span class="na">itemtype=</span><span class="s">&quot;http://schema.org/CreativeWork&quot;</span><span class="nt">&gt;</span>
        <span class="nt">&lt;span</span> <span class="na">itemprop=</span><span class="s">&quot;text&quot;</span><span class="nt">&gt;</span>“We accept the love we think we deserve.”<span class="nt">&lt;/span&gt;</span>
        <span class="nt">&lt;small</span> <span class="na">itemprop=</span><span class="s">&quot;author&quot;</span><span class="nt">&gt;</span>Stephen Chbosky<span class="nt">&lt;/small&gt;</span>
        <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;tags&quot;</span><span class="nt">&gt;</span>
            Tags:
            <span class="nt">&lt;meta</span> <span class="na">itemprop=</span><span class="s">&quot;keywords&quot;</span> <span class="na">content=</span><span class="s">&quot;inspirational,love&quot;</span><span class="nt">&gt;</span>

            <span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">&quot;/tag/inspirational/page/1/&quot;</span><span class="nt">&gt;</span>inspirational<span class="nt">&lt;/a&gt;</span>

            <span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">&quot;/tag/love/page/1/&quot;</span><span class="nt">&gt;</span>love<span class="nt">&lt;/a&gt;</span>

        <span class="nt">&lt;/div&gt;</span>
    <span class="nt">&lt;/div&gt;</span>
&gt;&gt;&gt; print quote.css(&#39;span&#39;).extract_first()
<span class="nt">&lt;span</span> <span class="na">itemprop=</span><span class="s">&quot;text&quot;</span><span class="nt">&gt;</span>“We accept the love we think we deserve.”<span class="nt">&lt;/span&gt;</span>
&gt;&gt;&gt; print quote.css(&#39;span::text&#39;).extract_first()  # texto
“We accept the love we think we deserve.”
&gt;&gt;&gt; quote.css(&#39;small::text&#39;).extract_first()  # autor
    u&#39;Stephen Chbosky&#39;
&gt;&gt;&gt; 
&gt;&gt;&gt; # para a lista de tags, usamos .extract() em vez de .extract_first()
&gt;&gt;&gt; quote.css(&#39;.tags a::text&#39;).extract()
    [u&#39;inspirational&#39;, u&#39;love&#39;]
&gt;&gt;&gt;
</pre></div>


<p>Com o resultado da exploração inicial acima, podemos começar escrevendo um
spider assim, num arquivo <code>quote_spider.py</code>:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;quotes&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://spidyquotes.herokuapp.com/&#39;</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;texto&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s1">&#39;autor&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;small::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.tags a::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="p">}</span>
</pre></div>


<p>Se você rodar esse spider com:</p>
<div class="highlight"><pre><span></span>scrapy runspider quote_spider.py -o quotes.csv
</pre></div>


<p>Você obterá os dados das citações da primeira página no arquivo <code>quotes.csv</code>.
Só está faltando agora seguir o link para a próxima página, o que você também
pode descobrir com mais alguma exploração no shell:</p>
<div class="highlight"><pre><span></span>&gt;&gt;&gt; response.css(&#39;li.next&#39;)
    [&lt;Selector xpath=u&quot;descendant-or-self::li[@class and contains(concat(&#39; &#39;, normalize-space(@class), &#39; &#39;), &#39; next &#39;)]&quot; data=u&#39;&lt;li class=&quot;next&quot;&gt;\n                &lt;a hre&#39;&gt;]
&gt;&gt;&gt; response.css(&#39;li.next a&#39;)
    [&lt;Selector xpath=u&quot;descendant-or-self::li[@class and contains(concat(&#39; &#39;, normalize-space(@class), &#39; &#39;), &#39; next &#39;)]/descendant-or-self::*/a&quot; data=u&#39;&lt;a href=&quot;/page/2/&quot;&gt;Next &lt;span aria-hidde&#39;&gt;]
&gt;&gt;&gt; response.css(&#39;li.next a::attr(&quot;href&quot;)&#39;).extract_first()
    u&#39;/page/2/&#39;
&gt;&gt;&gt; # o link é relativo, temos que joinear com a URL da resposta:
&gt;&gt;&gt; response.urljoin(response.css(&#39;li.next a::attr(&quot;href&quot;)&#39;).extract_first())
    u&#39;http://spidyquotes.herokuapp.com/page/2/&#39;
</pre></div>


<p>Juntando isso com o spider, ficamos com:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;quotes&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://spidyquotes.herokuapp.com/&#39;</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;texto&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s1">&#39;autor&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;small::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.tags a::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="p">}</span>
        <span class="n">link_next</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(&quot;href&quot;)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">link_next</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">link_next</span><span class="p">))</span>
</pre></div>


<p>Agora, se você rodar esse spider novamente com:</p>
<div class="highlight"><pre><span></span>scrapy runspider quote_spider.py
</pre></div>


<p>Perceberá que ainda assim ele vai extrair apenas os items da primeira página, e a segunda página
vai falhar com um código HTTP 429, com a seguinte mensagem no log:</p>
<div class="highlight"><pre><span></span>2015-11-15 00:06:15 [scrapy] DEBUG: Crawled (429) &lt;GET http://spidyquotes.herokuapp.com/page/2/&gt; (referer: http://spidyquotes.herokuapp.com/)
2015-11-15 00:06:15 [scrapy] DEBUG: Ignoring response &lt;429 http://spidyquotes.herokuapp.com/page/2/&gt;: HTTP status code is not handled or not allowed
2015-11-15 00:06:15 [scrapy] INFO: Closing spider (finished)
</pre></div>


<p><center>
  <img alt="" src="http://httpstatusdogs.com/wp-content/uploads/2011/12/429.jpg" />
</center></p>
<p>O status HTTP 429 é usado para indicar que o servidor está recebendo muitas
requisições do mesmo cliente num curto período de tempo.</p>
<p>No caso do nosso site, podemos simular o problema no próprio browser se
apertarmos o botão atualizar várias vezes no mesmo segundo:</p>
<p><center>
  <img alt="" src="http://i.imgur.com/V3arr9E.jpg" />
</center></p>
<p>Neste caso, a mensagem no próprio site já nos diz o problema e a solução: o máximo de
requisições permitido é uma a cada segundo, então podemos resolver o problema setando
a configuração <code>DOWNLOAD_DELAY</code> para 1.5, deixando uma margem decente para podermos
fazer crawling sabendo que estamos respeitando a política.</p>
<p>Como esta é uma necessidade comum para alguns sites, o Scrapy também permite
você configurar este comportamento diretamente no spider, setando o atributo de
classe <code>download_delay</code>:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;quotes&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://spidyquotes.herokuapp.com/&#39;</span>
    <span class="p">]</span>
    <span class="n">download_delay</span> <span class="o">=</span> <span class="mf">1.5</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;texto&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s1">&#39;autor&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;small::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.tags a::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="p">}</span>
        <span class="n">link_next</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(&quot;href&quot;)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">link_next</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">link_next</span><span class="p">))</span>
</pre></div>


<h3>Usando extruct para microdata</h3>
<p>Se você é um leitor perspicaz, deve ter notado que o markup HTML tem umas
marcações adicionais ao HTML normal, usando atributos <code>itemprop</code> e <code>itemtype</code>.
Trata-se de um mecanismo chamado
<a href="https://en.wikipedia.org/wiki/Microdata_(HTML)">Microdata</a>, <a href="http://www.w3.org/TR/microdata/">especificado pela
W3C</a> e feito justamente para facilitar a
tarefa de extração automatizada. Vários sites suportam este tipo de marcação,
alguns exemplos famosos são <a href="http://www.yelp.com">Yelp</a>, <a href="http://www.theguardian.co.uk">The
Guardian</a>, <a href="http://lemonde.fr">LeMonde</a>, etc.</p>
<p>Quando um site tem esse tipo de marcação para o conteúdo que você está
interessado, você pode usar o extrator de microdata da biblioteca
<a href="https://pypi.python.org/pypi/extruct">extruct</a>.</p>
<p>Instale a biblioteca extruct com:</p>
<div class="highlight"><pre><span></span>pip install extruct
</pre></div>


<p>Veja como fica o código usando a lib:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">extruct.w3cmicrodata</span> <span class="kn">import</span> <span class="n">LxmlMicrodataExtractor</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;quotes-microdata&quot;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://spidyquotes.herokuapp.com/&#39;</span><span class="p">]</span>
    <span class="n">download_delay</span> <span class="o">=</span> <span class="mf">1.5</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">extractor</span> <span class="o">=</span> <span class="n">LxmlMicrodataExtractor</span><span class="p">()</span>
        <span class="n">items</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body_as_unicode</span><span class="p">(),</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)[</span><span class="s1">&#39;items&#39;</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">items</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">it</span><span class="p">[</span><span class="s1">&#39;properties&#39;</span><span class="p">]</span>

        <span class="n">link_next</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(&quot;href&quot;)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">link_next</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">link_next</span><span class="p">))</span>
</pre></div>


<p>Usando microdata você reduz sobremaneira os problemas de mudanças de leiaute,
pois o desenvolvedor do site ao colocar o markup microdata se compromete a
mantê-lo atualizado.</p>
<h3>Lidando com leiaute de tabelas:</h3>
<p>Agora, vamos extrair os mesmos dados mas para um markup faltando bom-gosto:
<a href="http://spidyquotes.herokuapp.com/tableful/">http://spidyquotes.herokuapp.com/tableful/</a></p>
<p>Para lidar com esse tipo de coisa, a dica é: <strong>aprenda XPath</strong>, vale a pena!</p>
<p>Comece aqui: <a href="http://www.slideshare.net/scrapinghub/xpath-for-web-scraping">http://www.slideshare.net/scrapinghub/xpath-for-web-scraping</a></p>
<blockquote>
<p><em>O domínio de XPath diferencia os gurus dos gafanhotos. -- Elias Dorneles, 2014</em></p>
</blockquote>
<p>Como o markup HTML dessa página não uma estrutura boa, em vez de fazer scraping
baseado nas classes CSS ou ids dos elementos, com XPath podemos fazer baseando-se
na estrutura e nos padrões presentes no conteúdo.</p>
<p>Por exemplo, se você abrir o shell para a página
<a href="http://spidyquotes.herokuapp.com/tableful">http://spidyquotes.herokuapp.com/tableful</a>, usando a expressão a seguir
retorna os os nós <code>tr</code> (linhas da tabela) que contém os textos das citações,
usando uma condição para pegar apenas linhas que estão imediatamente antes de
linhas cujo texto comece com <code>"Tags: "</code>:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="nt">response</span><span class="p">.</span><span class="nc">xpath</span><span class="o">(</span><span class="s1">&#39;//tr</span><span class="cp">[</span><span class="nx">.</span><span class="p">/</span><span class="nx">following</span><span class="na">-sibling</span><span class="nl">::tr</span><span class="err">[</span><span class="mi">1</span><span class="cp">]</span><span class="s1">/td</span><span class="cp">[</span><span class="nx">starts</span><span class="na">-with</span><span class="p">(</span><span class="nx">.</span><span class="p">,</span> <span class="s2">&quot;Tags:&quot;</span><span class="p">)</span><span class="cp">]</span><span class="s1">]&#39;</span><span class="o">)</span>
<span class="cp">[</span><span class="o">&lt;</span><span class="nx">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span> <span class="n">data</span><span class="o">=</span><span class="nx">u</span><span class="s1">&#39;&lt;tr style=&quot;border-bottom: 0px; &quot;&gt;</span><span class="se">\n</span><span class="s1">      &#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="nx">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span> <span class="n">data</span><span class="o">=</span><span class="nx">u</span><span class="s1">&#39;&lt;tr style=&quot;border-bottom: 0px; &quot;&gt;</span><span class="se">\n</span><span class="s1">      &#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="nx">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span> <span class="n">data</span><span class="o">=</span><span class="nx">u</span><span class="s1">&#39;&lt;tr style=&quot;border-bottom: 0px; &quot;&gt;</span><span class="se">\n</span><span class="s1">      &#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="nx">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span> <span class="n">data</span><span class="o">=</span><span class="nx">u</span><span class="s1">&#39;&lt;tr style=&quot;border-bottom: 0px; &quot;&gt;</span><span class="se">\n</span><span class="s1">      &#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="nx">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span> <span class="n">data</span><span class="o">=</span><span class="nx">u</span><span class="s1">&#39;&lt;tr style=&quot;border-bottom: 0px; &quot;&gt;</span><span class="se">\n</span><span class="s1">      &#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="nx">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span> <span class="n">data</span><span class="o">=</span><span class="nx">u</span><span class="s1">&#39;&lt;tr style=&quot;border-bottom: 0px; &quot;&gt;</span><span class="se">\n</span><span class="s1">      &#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="nx">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span> <span class="n">data</span><span class="o">=</span><span class="nx">u</span><span class="s1">&#39;&lt;tr style=&quot;border-bottom: 0px; &quot;&gt;</span><span class="se">\n</span><span class="s1">      &#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="nx">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span> <span class="n">data</span><span class="o">=</span><span class="nx">u</span><span class="s1">&#39;&lt;tr style=&quot;border-bottom: 0px; &quot;&gt;</span><span class="se">\n</span><span class="s1">      &#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="nx">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span> <span class="n">data</span><span class="o">=</span><span class="nx">u</span><span class="s1">&#39;&lt;tr style=&quot;border-bottom: 0px; &quot;&gt;</span><span class="se">\n</span><span class="s1">      &#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="nx">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span> <span class="n">data</span><span class="o">=</span><span class="nx">u</span><span class="s1">&#39;&lt;tr style=&quot;border-bottom: 0px; &quot;&gt;</span><span class="se">\n</span><span class="s1">      &#39;</span><span class="o">&gt;</span><span class="cp">]</span>
</pre></div>


<p>Para extrair os dados, precisamos de alguma exploração:</p>
<div class="highlight"><pre><span></span>&gt;&gt;&gt; quote = response.xpath(&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;)[0]
&gt;&gt;&gt; print quote.extract()
<span class="nt">&lt;tr</span> <span class="na">style=</span><span class="s">&quot;border-bottom: 0px; &quot;</span><span class="nt">&gt;</span>
            <span class="nt">&lt;td</span> <span class="na">style=</span><span class="s">&quot;padding-top: 2em;&quot;</span><span class="nt">&gt;</span>“We accept the love we think we deserve.” Author: Stephen Chbosky<span class="nt">&lt;/td&gt;</span>
                    <span class="nt">&lt;/tr&gt;</span>
&gt;&gt;&gt; quote.xpath(&#39;string(.)&#39;).extract_first()
    u&#39;\n            \u201cWe accept the love we think we deserve.\u201d Author: Stephen Chbosky\n        &#39;
&gt;&gt;&gt; quote.xpath(&#39;normalize-space(.)&#39;).extract_first()
    u&#39;\u201cWe accept the love we think we deserve.\u201d Author: Stephen Chbosky&#39;
</pre></div>


<p>Note como não tem marcação separando o autor do conteúdo, apenas uma string
"Author:".  Então podemos usar o método <code>.re()</code> da classe seletor, que nos
permite usar uma expressão regular:</p>
<div class="highlight"><pre><span></span>&gt;&gt;&gt; text, author = quote.xpath(&#39;normalize-space(.)&#39;).re(&#39;(.+) Author: (.+)&#39;)
&gt;&gt;&gt; text
    u&#39;\u201cWe accept the love we think we deserve.\u201d&#39;
&gt;&gt;&gt; author
    u&#39;Stephen Chbosky&#39;
</pre></div>


<p>O código final do spider fica:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;quotes-tableful&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://spidyquotes.herokuapp.com/tableful&#39;</span><span class="p">]</span>
    <span class="n">download_delay</span> <span class="o">=</span> <span class="mf">1.5</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">quotes_xpath</span> <span class="o">=</span> <span class="s1">&#39;//tr[./following-sibling::tr[1]/td[starts-with(., &quot;Tags:&quot;)]]&#39;</span>

        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="n">quotes_xpath</span><span class="p">):</span>
            <span class="n">texto</span><span class="p">,</span> <span class="n">autor</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;normalize-space(.)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="s1">&#39;(.+) Author: (.+)&#39;</span><span class="p">)</span>
            <span class="n">tags</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;./following-sibling::tr[1]//a/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="k">yield</span> <span class="nb">dict</span><span class="p">(</span><span class="n">texto</span><span class="o">=</span><span class="n">texto</span><span class="p">,</span> <span class="n">autor</span><span class="o">=</span><span class="n">autor</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="n">tags</span><span class="p">)</span>

        <span class="n">link_next</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//a[contains(., &quot;Next&quot;)]/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">link_next</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">link_next</span><span class="p">))</span>
</pre></div>


<p>Note como o uso de XPath permitiu vincularmos elementos de acordo com o conteúdo
tanto no caso das tags quanto no caso do link para a próxima página.</p>
<h3>Lidando com dados dentro do código</h3>
<p>Olhando o código-fonte da versão do site: <a href="http://spidyquotes.herokuapp.com/js/">http://spidyquotes.herokuapp.com/js/</a>
vemos que os dados que queremos estão todos num bloco de código Javascript,
dentro de um array estático. E agora?</p>
<p>A dica aqui é usar a lib <a href="https://github.com/redapple/js2xml">js2xml</a> para
converter o código Javascript em XML e então usar XPath ou CSS em cima do XML
resultante para extrair os dados que a gente quer.</p>
<p>Instale a biblioteca js2xml com:</p>
<div class="highlight"><pre><span></span>pip install js2xml
</pre></div>


<p>Exemplo no shell:</p>
<div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">shell</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">spidyquotes</span><span class="o">.</span><span class="n">herokuapp</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">js</span><span class="o">/</span>

<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">js2xml</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">script</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//script[contains(., &quot;var data =&quot;)]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sel</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Selector</span><span class="p">(</span><span class="n">_root</span><span class="o">=</span><span class="n">js2xml</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">script</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span><span class="p">)</span>
    <span class="p">[</span><span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span> <span class="n">data</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;&lt;object&gt;&lt;property name=&quot;author&quot;&gt;&lt;object&gt;&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span> <span class="n">data</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;&lt;object&gt;&lt;property name=&quot;author&quot;&gt;&lt;object&gt;&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span> <span class="n">data</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;&lt;object&gt;&lt;property name=&quot;author&quot;&gt;&lt;object&gt;&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span> <span class="n">data</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;&lt;object&gt;&lt;property name=&quot;author&quot;&gt;&lt;object&gt;&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span> <span class="n">data</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;&lt;object&gt;&lt;property name=&quot;author&quot;&gt;&lt;object&gt;&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span> <span class="n">data</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;&lt;object&gt;&lt;property name=&quot;author&quot;&gt;&lt;object&gt;&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span> <span class="n">data</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;&lt;object&gt;&lt;property name=&quot;author&quot;&gt;&lt;object&gt;&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span> <span class="n">data</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;&lt;object&gt;&lt;property name=&quot;author&quot;&gt;&lt;object&gt;&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span> <span class="n">data</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;&lt;object&gt;&lt;property name=&quot;author&quot;&gt;&lt;object&gt;&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span> <span class="n">data</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;&lt;object&gt;&lt;property name=&quot;author&quot;&gt;&lt;object&gt;&#39;</span><span class="o">&gt;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">quote</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">quote</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;string(./property[@name=&quot;text&quot;])&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
    <span class="sa">u</span><span class="s1">&#39;</span><span class="se">\u201c</span><span class="s1">We accept the love we think we deserve.</span><span class="se">\u201d</span><span class="s1">&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">quote</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;string(./property[@name=&quot;author&quot;]//property[@name=&quot;name&quot;])&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
    <span class="sa">u</span><span class="s1">&#39;Stephen Chbosky&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">quote</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;./property[@name=&quot;tags&quot;]//string/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
    <span class="p">[</span><span class="sa">u</span><span class="s1">&#39;inspirational&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;love&#39;</span><span class="p">]</span>
</pre></div>


<p>O código final fica:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">import</span> <span class="nn">js2xml</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;quotes-js&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://spidyquotes.herokuapp.com/js/&#39;</span><span class="p">]</span>
    <span class="n">download_delay</span> <span class="o">=</span> <span class="mf">1.5</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">script</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//script[contains(., &quot;var data =&quot;)]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="n">sel</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Selector</span><span class="p">(</span><span class="n">_root</span><span class="o">=</span><span class="n">js2xml</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">script</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//var[@name=&quot;data&quot;]/array/object&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;texto&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;string(./property[@name=&quot;text&quot;])&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s1">&#39;autor&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span>
                    <span class="s1">&#39;string(./property[@name=&quot;author&quot;]//property[@name=&quot;name&quot;])&#39;</span>
                <span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;./property[@name=&quot;tags&quot;]//string/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">link_next</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(&quot;href&quot;)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">link_next</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">link_next</span><span class="p">))</span>
</pre></div>


<p>Fica um pouco obscuro pela transformação de código Javascript em XML, mas a
extração fica mais confiável do que hacks baseados em expressões regulares.</p>
<h3>Lidando com AJAX</h3>
<p>Agora, vamos para a versão AJAX com scroll infinito: <a href="http://spidyquotes.herokuapp.com/scroll/">http://spidyquotes.herokuapp.com/scroll/</a></p>
<p>Se você observar o código-fonte, verá que os dados não estão lá.  No fonte só
tem um código Javascript que busca os dados via AJAX, você pode ver isso
olhando a aba <em>Network</em> das ferramentas do browser (no meu caso Chrome, mas
no Firefox é similar).</p>
<p>Nesse caso, precisamos replicar essas requisições com o Scrapy, e tratar
os resultados de acordo com a resposta.</p>
<p>Explorando no shell, vemos que o conteúdo é JSON:</p>
<div class="highlight"><pre><span></span>scrapy shell http://spidyquotes.herokuapp.com/api/quotes?page=1

&gt;&gt;&gt; response.headers
{&#39;Content-Type&#39;: &#39;application/json&#39;,
 &#39;Date&#39;: &#39;Sun, 15 Nov 2015 22:18:29 GMT&#39;,
 &#39;Server&#39;: &#39;gunicorn/19.3.0&#39;,
 &#39;Via&#39;: &#39;1.1 vegur&#39;}
</pre></div>


<p>Portanto, podemos simplesmente usar o módulo JSON da biblioteca padrão e ser feliz:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">json</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="p">[</span><span class="sa">u</span><span class="s1">&#39;has_next&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;quotes&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;tag&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;page&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;top_ten_tags&#39;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;has_next&#39;</span><span class="p">]</span>
<span class="bp">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;quotes&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="p">{</span><span class="sa">u</span><span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="p">{</span><span class="sa">u</span><span class="s1">&#39;goodreads_link&#39;</span><span class="p">:</span> <span class="sa">u</span><span class="s1">&#39;/author/show/12898.Stephen_Chbosky&#39;</span><span class="p">,</span>
  <span class="sa">u</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="sa">u</span><span class="s1">&#39;Stephen Chbosky&#39;</span><span class="p">},</span>
 <span class="sa">u</span><span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="p">[</span><span class="sa">u</span><span class="s1">&#39;inspirational&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;love&#39;</span><span class="p">],</span>
 <span class="sa">u</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="sa">u</span><span class="s1">&#39;</span><span class="se">\u201c</span><span class="s1">We accept the love we think we deserve.</span><span class="se">\u201d</span><span class="s1">&#39;</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;page&#39;</span><span class="p">]</span>
<span class="mi">1</span>
</pre></div>


<p>Código final do spider fica:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">import</span> <span class="nn">json</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;quotes-scroll&#39;</span>
    <span class="n">quotes_base_url</span> <span class="o">=</span> <span class="s1">&#39;http://spidyquotes.herokuapp.com/api/quotes?page=</span><span class="si">%s</span><span class="s1">&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="n">quotes_base_url</span> <span class="o">%</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">download_delay</span> <span class="o">=</span> <span class="mf">1.5</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;quotes&#39;</span><span class="p">,</span> <span class="p">[]):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;texto&#39;</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span>
                <span class="s1">&#39;autor&#39;</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;author&#39;</span><span class="p">][</span><span class="s1">&#39;name&#39;</span><span class="p">],</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;tags&#39;</span><span class="p">],</span>
            <span class="p">}</span>
        <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;has_next&#39;</span><span class="p">]:</span>
            <span class="n">next_page</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;page&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quotes_base_url</span> <span class="o">%</span> <span class="n">next_page</span><span class="p">)</span>
</pre></div>


<p>Ao lidar com requisições desse tipo, uma ferramenta útil que pode ser o
<a href="https://pypi.python.org/pypi/minreq">minreq</a>, instale com: <code>pip install
minreq</code>.</p>
<p>O minreq tenta encontrar a requisição mínima necessária para replicar
uma requisição do browser, e pode opcionalmente mostrar como montar
um objeto <code>scrapy.Request</code> equivalente.</p>
<p>Rode o minreq com:</p>
<div class="highlight"><pre><span></span>minreq --action print_scrapy_request
</pre></div>


<p>Ele fica esperando você colar uma requisição no formato cURL. Para isto,
encontre a requisição AJAX que você quer replicar na aba Network do browser, e
use o recurso "Copy as cURL":</p>
<p><img alt="" src="http://i.imgur.com/hqz9b58.jpg" /></p>
<p>Cole no prompt do minreq, e espere ele fazer a mágica. =)</p>
<blockquote>
<p><strong>Nota:</strong> O minreq está em estágio pre-alpha, você provavelmente vai
encontrar bugs -- por favor reporte no GitHub.</p>
</blockquote>
<h2>Rodando no Scrapy Cloud</h2>
<p>O <a href="http://scrapinghub.com/platform/">Scrapy Cloud</a> é a plataforma PaaS para
rodar crawlers na nuvem, o que permite evitar uma série de preocupações com
infraestrutura.</p>
<p>Funciona como um "Heroku para crawlers", você faz deploy do seu projeto Scrapy
e configura jobs para rodar spiders periodicamente.  Você pode também
configurar scripts Python para rodar periodicamente, os quais podem gerenciar o
escalonamento dos spiders.</p>
<p>Comece criando uma conta free forever em: <a href="http://try.scrapinghub.com/free">http://try.scrapinghub.com/free</a></p>
<h3>Criação do projeto</h3>
<p>Até aqui nossos exemplos foram simplesmente rodando spiders com <code>scrapy runspider</code>.
Para fazer o deploy, chegou a hora de criar um projeto Scrapy propriamente dito.</p>
<p>Para criar um projeto, basta rodar o comando <code>scrapy startproject</code> passando o nome do projeto:</p>
<div class="highlight"><pre><span></span>scrapy startproject quotes_crawler
</pre></div>


<p>Feito isso, entre no diretório do projeto com <code>cd quotes_crawler</code> e copie os
arquivos com spiders para dentro do diretório <code>quotes_crawler/spiders</code>.
Certifique-se de usar um nome único para cada spider.</p>
<p>A partir desse momento, você deve ser capaz de rodar cada spider em separado usando o comando:</p>
<div class="highlight"><pre><span></span>scrapy crawl NOME_DO_SPIDER
</pre></div>


<blockquote>
<p><strong>Nota:</strong> Dependendo do caso, é legal começar com um projeto desde o começo,
para já fazer tudo de maneira estruturada. Pessoalmente, eu gosto de começar
com spiders em arquivos soltos, quando estou apenas testando a viabilidade de
um crawler. Crio um projeto apenas quando vou colaborar no código com outras
pessoas ou fazer deploy no Cloud, nessa hora já é interessante que fique tudo
estruturado e fácil de crescer dentro de um projeto.</p>
</blockquote>
<h3>Configuração no Scrapy Cloud</h3>
<p>Antes do deploy, você precisa criar um projeto no Scrapy Cloud. Na tela
inicial, clique no botão adicionar uma organização:</p>
<p><center>
  <img alt="" src="http://i.imgur.com/9fsBv4I.png" />
</center></p>
<p>Dê um nome para a organização e confirme:</p>
<p><center>
  <img alt="" src="http://i.imgur.com/GvfEXzu.png" />
</center></p>
<p>Em seguida, adicione um serviço do para hospedar o seu serviço, clicando no
botão "+ Service" que aparece dentro da organização criada:</p>
<p><center>
  <img alt="" src="http://i.imgur.com/D0VTJLc.png" />
</center></p>
<p>Preencha os dados do seu projeto e confirme:</p>
<p><center>
  <img alt="" src="http://i.imgur.com/05Hvbu3.png" />
</center></p>
<p>Depois disso, clique no nome do serviço na página inicial para acessar o local
onde seu projeto estará disponível:</p>
<p><center>
  <img alt="" src="http://i.imgur.com/OIZLxYA.png" />
</center></p>
<p>Note o número identificador do seu projeto: você usará esse identificador na
hora fazer o deploy.</p>
<p><center>
  <img alt="" src="http://i.imgur.com/ErsMJbB.png" />
</center></p>
<h3>Instalando e configurando shub</h3>
<p>A maneira mais fácil de fazer deploy no Scrapy Cloud é usando a ferramenta
<a href="http://doc.scrapinghub.com/shub.html">shub</a>, cliente da linha de comando
para o Scrapy Cloud e demais serviços da Scrapinghub.</p>
<p>Instale-a com:</p>
<div class="highlight"><pre><span></span>pip install shub --upgrade
</pre></div>


<p>Faça login com o shub, usando o comando:</p>
<div class="highlight"><pre><span></span>shub login
</pre></div>


<p>Informe sua API key conforme for solicitado (<a href="https://dash.scrapinghub.com/account/apikey">descubra aqui sua API
key</a>).</p>
<blockquote>
<p><strong>Dica:</strong> Ao fazer login, o shub criará no arquivo <code>~/.netrc</code> uma entrada
configurada para usar sua API key.  Esse arquivo também é usado pelo <code>curl</code>,
o que é útil para quando você deseje fazer requisições HTTP para as APIs na
linha de comando.</p>
</blockquote>
<h3>Preparando o projeto</h3>
<p>Antes de fazer deploy do projeto, precisamos fazer deploy das dependências no
Scrapy Cloud.
Crie um arquivo <code>requirements-deploy.txt</code> com o seguinte conteúdo:</p>
<div class="highlight"><pre><span></span>extruct
js2xml
slimit
ply
</pre></div>


<p>Rode o comando:</p>
<div class="highlight"><pre><span></span>shub deploy-reqs PROJECT_ID requirements-deploy.txt
</pre></div>


<p>Substitua <code>PROJECT_ID</code> pelo id do seu projeto (neste caso, 27199).</p>
<h4>Deploy das dependências</h4>
<p>Agora faça deploy do projeto com o comando:</p>
<div class="highlight"><pre><span></span>shub deploy -p PROJECT_ID
</pre></div>


<p>Novamente, substituindo <code>PROJECT_ID</code> pelo id do seu projeto (neste caso, 27199)</p>
<p>Se tudo deu certo, você verá algo como</p>
<div class="highlight"><pre><span></span>$ shub deploy -p <span class="m">27199</span>
Packing version <span class="m">1447628479</span>
Deploying to Scrapy Cloud project <span class="s2">&quot;27199&quot;</span>
<span class="o">{</span><span class="s2">&quot;status&quot;</span>: <span class="s2">&quot;ok&quot;</span>, <span class="s2">&quot;project&quot;</span>: <span class="m">27199</span>, <span class="s2">&quot;version&quot;</span>: <span class="s2">&quot;1447628479&quot;</span>, <span class="s2">&quot;spiders&quot;</span>: <span class="m">5</span><span class="o">}</span>
Run your spiders at: https://dash.scrapinghub.com/p/27199/
</pre></div>


<p>Agora você pode ir para a URL indicada (neste caso, <a href="https://dash.scrapinghub.com/p/27199/">https://dash.scrapinghub.com/p/27199/</a>)
e agendar jobs dos spiders usando o botão "Schedule".</p>
<blockquote>
<p><strong>Nota:</strong> opcionalmente, você pode configurar o identificador do projeto no
arquivo <code>scrapy.cfg</code>, para não precisar ter que lembrar a cada vez.</p>
</blockquote>
<p>Para configurar um spider para rodar periodicamente, utilize a aba "Periodic
Jobs", no menu à esquerda.</p>
<h1>The End</h1>
<p>Era isso, se você chegou até aqui, parabéns e obrigado pela atenção! :)</p>
<p>Você pode conferir o código do projeto final em: <a href="https://github.com/eliasdorneles/quotes_crawler">https://github.com/eliasdorneles/quotes_crawler</a></p>
<p>Para obter ajuda, pergunte no <a href="http://pt.stackoverflow.com/tags/scrapy">Stackoverflow em Português usando a tag
scrapy</a> ou pergunte em inglês no
<a href="http://stackoverflow.com/tags/scrapy">Stackoverflow em inglês</a> ou na <a href="https://groups.google.com/forum/#!forum/scrapy-users">lista de
e-mail scrapy-users</a>.</p>
<p>Obrigado Valdir pela ajuda com a montagem desse tutorial, tanto no desenvolvimento
do app <code>spidyquotes</code> quanto na escrita do material. <em>You rock, dude!</em></p>
</section>

        <aside id="sidebar">
                <div class="widget">
                        <h2>Categories</h2>
                        <ul>
                           <li ><a href="/category/blog.html">blog</a></li>
                        </ul>
                </div>
        </aside><!-- /#sidebar -->

        <hr />
        <footer class="footer-menu">
            <a href="#top">Back to the top</a>
        </footer>
</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-1881525-7', 'auto');
  ga('send', 'pageview');

</script></body>
</html>